---
---

@inproceedings{10.1007/978-3-031-51026-7_26,
  abbr = {ICIAP},
  selected = {true},
  preview = {scene_obj.png},
  bibtex_show={true},
  language= {en},
  doi={10.1007/978-3-031-51026-7_26},
  url={https://doi.org/10.1007/978-3-031-51026-7_26},
  author={Russo, Alessandro
    and Spanio, Matteo
    and Canazza, Sergio},
  editor={Foresti, Gian Luca
    and Fusiello, Andrea
    and Hancock, Edwin},
  title={Enhancing Preservation and Restoration of Open Reel Audio Tapes Through Computer Vision},
  booktitle={Image Analysis and Processing - ICIAP 2023 Workshops},
  year={2024},
  publisher={Springer Nature Switzerland},
  address={Cham},
  pages={297--308},
  abstract={Analog audio documents inevitably face degradation over time, posing a challenge for preserving their audio content and ensuring the integrity of the recordings. Analog document preservation is one of the main research topics of interest of the Centro di Sonologia Computazionale (CSC) of the Department of Information Engineering of the University of Padua, which over the years developed and implemented a methodology for preservation that includes, among other things, the video recording of the digitization process of the open-reel tapes for documenting irregularities on the top of their surface. Together with the corpus of digitized high-quality audio recordings, this led to the creation of an internal archive of video documents. This paper presents a software application that leverages computer vision techniques to automatically detect Irregularities on open-reel audio tapes, analyzing the video documents produced during the digitization interventions. The software employs a frame-by-frame analysis to automatically identify and highlight points of interest that may indicate tape damages, splices, and other Irregularities. The software uses Generalized Hough Transform and SURF algorithms to locate regions of interest within the tape. The proposed software is also part of the MPAI/IEEE-CAE ARP standard developed by Audio Innova s.r.l., spin-off of the CSC, and it may offer a robust and efficient solution for analyzing open-reel audio tapes, supporting archivists and musicologists in their activities.},
  isbn={978-3-031-51026-7},
  google_scholar_id={9yKSN-GCB0IC},
}

@thesis{https://doi.org/10.13140/rg.2.2.36838.50247,
  bibtex_show={true},
  pdf = {A_study_on_Equalization_Curve_Detection.pdf},
  doi = {10.13140/RG.2.2.36838.50247},
  url = {https://rgdoi.net/10.13140/RG.2.2.36838.50247},
  html = {https://matteospanio.gitlab.io/mpai-audio-analyser/},
  author = {Spanio, Matteo},
  language = {en},
  title = {A study on Equalization Curve Detection in Audio Tape Digitization process using Artificial Intelligence},
  publisher = {Unpublished},
  year = {2023},
  google_scholar_id={d1gkVwhDpl0C},
  abstract = {In recent decades, archives have seen a rapid change in the media used to store sound information, and many of these media are rich in obsolete material that risks becoming unusable due to aging. Therefore, it is necessary to digitize sound documents in order to make them durable over time. However, during the digitization process, errors such as applying an incorrect equalization curve or playing back the tape at the wrong speed can lead to the acquisition of inauthentic material. This work focuses on studying the detection of possible errors due to incorrect equalization curve settings and tape playback speed during the transfer of material from analog to digital, verifying if and how it is possible to detect them using methods specific to Artificial Intelligence (clustering and classification). The results of this research demonstrate that these algorithms may offer good precision in detecting errors and have the potential to automate the verification process, ensuring the preservation of valid information for a longer period of time, but before they can be used in a real-world scenario, they must be further improved.},
}

@thesis{https://doi.org/10.13140/rg.2.2.17327.82088,
  bibtex_show={true},
  pdf = {TUTTI_QUANTI_VOGLION_FARE_JAZZ_Contamina.pdf},
  doi = {10.13140/RG.2.2.17327.82088},
  url = {https://rgdoi.net/10.13140/RG.2.2.17327.82088},
  author = {Spanio, Matteo},
  language = {it},
  title = {TUTTI QUANTI VOGLION FARE JAZZ - Contaminazioni Jazz nel repertorio clarinettistico del '900},
  type = {Master's Thesis},
  publisher = {Unpublished},
  google_scholar_id = {u-x6o8ySG0sC},
  year = {2021},
}

@misc{sphor:woo15,
  bibtex_show = {true},
  preview={variation-on-theme-from-arluna.jpg},
  author  = {Spohr, Louis and Spanio, Matteo},
  howpublished = {Edizioni Eufonia},
  title   = {Variations on Theme from Alruna},
  year         = {2019},
  url     = {https://www.edizionieufonia.it/homepage/variation-on-theme-from-arluna-for-clarinet-and-piano/},
  html     = {https://www.edizionieufonia.it/homepage/variation-on-theme-from-arluna-for-clarinet-and-piano/},
  note    = {Reduction for clarinet and piano by Matteo Spanio},
}

@thesis{https://doi.org/10.13140/rg.2.2.24143.56489,
  bibtex_show={true},
  pdf = {IL_CLARINETTO_ALLOPERA.pdf},
  abstract = {Attraverso le ricerche riportate in questa tesi si è voluto approfondire nelle sue diverse sfaccettature il ruolo del clarinetto e dei clarinettisti nella composizione delle Fantasie su temi d’Opera, genere molto diffuso all’inizio dell’Ottocento. Si sono visti nel dettaglio il Potpourri n. 2 per clarinetto e orchestra su Là ci darem la mano di Franz Danzi, le Variazioni su Euer Liebreiz, eure Schönheit in Si♭ maggiore dall’Opera Alruna di Louis Spohr e la Fantasia da Concerto su motivi del Rigoletto di Luigi Bassi. Per ogni brano si sono analizzate le origini storiche ponendo grande attenzione al contatto e talvolta alla collaborazione avvenuta tra compositore e strumentista. Lo scopo di tale lavoro non è quello di riportare semplicemente nozioni di valore storico, ma di riuscire a fornire al lettore l’idea di una corretta interpretazione filologica grazie al supporto della ricostruzione della vita dei personaggi coinvolti nella storia di questi brani; tenendo conto del fatto che il paesaggio sonoro in cui viviamo è diverso da quello di duecento anni fa e che le caratteristiche acustiche del clarinetto hanno subito numerose modifiche nel corso del tempo. La tesi è articolata in quattro capitoli e un’appendice in cui si può trovare una breve storia del clarinetto. Ogni capitolo è strutturato in maniera indipendente e può essere letto separatamente dal resto della tesi. Per ogni capitolo viene fornita un’introduzione al contesto storico e geografico a cui si fa riferimento, una storia dell’autore e dell’esecutore del pezzo e una breve analisi del brano considerato.},
  doi = {10.13140/RG.2.2.24143.56489},
  url = {https://rgdoi.net/10.13140/RG.2.2.24143.56489},
  author = {Spanio, Matteo},
  language = {it},
  title = {IL CLARINETTO ALL'OPERA},
  type = {Bachelor's Thesis},
  publisher = {Unpublished},
  year = {2019},
}

@article{bosi2024a,
  language= {en},
  preview={aes2024.jpg},
  abbr = {AES},
  bibtex_show={true},
  selected = {true},
  author={Bosi, Marina
    and Zanini, Fabio
    and Spanio, Matteo
    and Russo, Alessandro
    and Canazza Sergio},
  journal={Journal of the Audio Engineering Society},
  title={A novel derivative-based approach for the automatic detection of time-reversed audio in the MPAI/IEEE-CAE ARP international standard},
  year={2024},
  number={10190},
  abstract={The Moving Picture, Audio and Data Coding by Artificial Intelligence (MPAI) Context-based Audio Enhancement (CAE) Audio Recording Preservation (ARP) standard provides the technical specifications for a comprehensive framework for digitizing and preserving analog audio, specifically focusing on documents recorded on open-reel tapes. This paper presents a novel envelope derivative-based method designed to be integrated into the ARP standard, for detecting reverse audio sections during the preservation process. The primary objective of this method is to automatically identify segments of audio recorded in reverse. Leveraging derivative-based signal processing algorithms, the system enhances its capability to detect and reverse such sections, thereby reducing errors during the preservation process. This feature not only aids in identifying and correcting errors but also enhances  the efficiency of large-scale audio document archiving projects. The system's performance was evaluated using a diverse dataset that includes various musical genres and digitized tapes, demonstrating its strong potential and effectiveness across different types of audio content.},
  url={https://aes2.org/publications/elibrary-page/?id=22693},
}

@article{ieeeaccess2024,
  language= {en},
  preview={access-gagraphic-3474529.jpg},
  abbr = {IEEEAccess},
  pdf={IEEE_Access_2024.pdf},
  bibtex_show={true},
  html={https://ieeexplore.ieee.org/document/10705421},
  author={Bosi, Marina and Canazza, Sergio and Pretto, Niccolò and Russo, Alessandro and Spanio, Matteo},
  journal={IEEE Access},
  title={From Tape to Code: An International AI-Based Standard for Audio Cultural Heritage Preservation - Don’t Play That Song for me (If it’s Not Preserved With ARP!)},
  year={2024},
  volume={12},
  number={},
  pages={152544-152558},
  keywords={Artificial intelligence;Music;Cultural differences;Guidelines;Production;Magnetic recording;Surface treatment;Magnetoacoustic effects;Audio recording;Accuracy;Document handling;Audio systems;Artificial intelligence;audio documents preservation;audio restoration;IEEE standard;musicological analysis;MPAI standard},
  abstract={This article describes a novel technology for preserving audio documents archived on open-reel magnetic tapes forming the core of the Audio Recording Preservation (ARP) international standard. ARP is part of the Moving Picture, Audio, and Data Coding by Artificial Intelligence (MPAI) Context-based Audio Enhancement (CAE) standard, adopted by the IEEE Standard Association as IEEE 3302-2022 in December 2022. Leveraging automated Artificial Intelligence (AI) tools, ARP analyzes and extracts relevant information from digitized audio and video files of the tape’s corresponding digital Preservation Copy. This process includes identifying speed variations and surface irregularities on the tape, automatically rectifying errors to generate a restored Access Copy. By utilizing the ARP standard, archives gain a potent tool for expediting and optimizing the description of the preservation conditions of the tape, as well as automatically correcting any errors that may have occurred during the digitization process. This technology offers an efficient solution for managing both small and large collections of digitized analog items, marking a substantial advancement in the preservation of audio documents.},
  doi={10.1109/ACCESS.2024.3474529},
  google_scholar_id = {2osOgNQ5qMEC},
}

@inproceedings{Cinar2024,
  abbr = {IAI4CH},
  preview = {flowchart.png},
  bibtex_show={true},
  language = {en},
  author = {Çınar, Zafer and Russo, Alessandro and Spanio, Matteo and Pretto, Niccolò and Canazza, Sergio},
  title = {Filming the sound: Anomaly Detection on Audio Tape Recordings using Computer Vision Algorithms},
  booktitle = {Proceedings of the 3rd Workshop on Artificial Intelligence for Cultural Heritage (IAI4CH 2024) co-located with the 23rd International Conference of the Italian Association for Artificial Intelligence (AIxIA 2024)},
  series ={{CEUR} Workshop Proceedings},
  year = {2024},
  abstract = {The preservation of open-reel audio tapes is critical for maintaining valuable cultural and historical audio archives, yet current digitisation and analysis operations are often error-prone due to tape degradation and the long duration of the recordings. Considering the analog nature of this kind of recording, anomaly detection algorithms, applied to the video of the tape flowing on the playback head, can be used to detect errors and details with musicological value. This paper presents a new dataset of high-quality videos and a new algorithm for anomaly detection on audio tapes. Experimental results show notable improvements in detection performance, though false positives remain a challenge at higher speeds. Additionally, the new algorithm supports a wider range of playback speeds, improving its flexibility. This improvement is an important step towards a reliable implementation of the IEEE/MPAI CAE ARP standard (3302-2022).},
  publisher = {http://CEUR-WS.org},
  url = {https://ceur-ws.org/Vol-3865/},
  pdf = {https://ceur-ws.org/Vol-3865/13_paper.pdf},
  html = {https://doi.org/10.5281/zenodo.14028923},
  doi = {10.5281/zenodo.14028923},
}

@inproceedings{Spanio2024,
  abbr = {AIxIADC},
  author = {Spanio, Matteo},
  bibtex_show={true},
  language = {en},
  title = {Towards Emotionally Aware AI: Challenges and Opportunities in the Evolution of Multimodal Generative Models},
  booktitle = {Proceedings of the AIxIA Doctoral Consortium 2024 co-located with the 23nd International Conference of the Italian Association for Artificial Intelligence (AIxIA 2024)},
  series = {{CEUR} Workshop Proceedings},
  year = {2024},
  abstract = { The evolution of generative models in artificial intelligence (AI) has significantly expanded the capacity of machines to process and generate complex multimodal data such as text, images, audio, and video. Despite these advancements, the integration of emotional awareness remains an underexplored dimension. This paper examines the state of the art in multimodal generative AI, with a focus on existing models developed by major technology companies. It then proposes an approach to incorporate emotional awareness into AI models, which would enhance human-machine interaction by improving the interpretability and explainability of AI-generated decisions. The paper also addresses the challenges associated with building emotion-aware models, including the need for comprehensive multimodal datasets and the computational complexity of incorporating less-explored sensory modalities like olfaction and gustation. Finally, potential solutions are discussed, including the normalization of existing research data and the application of transfer learning to reduce resource demands. These steps are essential for advancing the field and unlocking the potential of emotion-aware multimodal AI in applications such as healthcare, robotics, and virtual assistants.},
  publisher = {http://CEUR-WS.org},
  url = {https://ceur-ws.org/Vol-3914/},
  pdf = {https://ceur-ws.org/Vol-3914/short84.pdf},
  google_scholar_id = {W7OEmFMy1HYC}
}

@misc{spanio2025arxiv,
  abbr = {arXiv},
  selected ={true},
  bibtex_show={true},
  abstract={In recent decades, neuroscientific and psychological research has traced direct relationships between taste and auditory perceptions. This article explores multimodal generative models capable of converting taste information into music, building on this foundational research. We provide a brief review of the state of the art in this field, highlighting key findings and methodologies. We present an experiment in which a fine-tuned version of a generative music model (MusicGEN) is used to generate music based on detailed taste descriptions provided for each musical piece. The results are promising: according the participants' (n=111) evaluation, the fine-tuned model produces music that more coherently reflects the input taste descriptions compared to the non-fine-tuned model. This study represents a significant step towards understanding and developing embodied interactions between AI, sound, and taste, opening new possibilities in the field of generative AI. We release our dataset, code and pre-trained model at: https://osf.io/xs5jy/.},
  language = {en},
  title={A Multimodal Symphony: Integrating Taste and Sound through Generative AI}, 
  author={Spanio, Matteo and Zampini, Massimiliano and Rodà, Antonio and Pierucci, Franco},
  year={2025},
  eprint={2503.02823},
  archivePrefix={arXiv},
  primaryClass={cs.SD},
  doi={10.48550/arXiv.2503.02823},
  url={https://arxiv.org/abs/2503.02823}, 
  pdf={https://arxiv.org/pdf/2503.02823},
  html={https://arxiv.org/html/2503.02823v1}
}

@misc{spanio2025torchfx,
      abbr = {arXiv},
      bibtex_show={true},
      language={en},
      title={TorchFX: A modern approach to Audio DSP with PyTorch and GPU acceleration},
      author={Spanio, Matteo and Rodà, Antonio},
      year={2025},
      eprint={2504.08624},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2504.08624},
      pdf={https://arxiv.org/pdf/2504.08624},
      html={https://arxiv.org/html/2504.08624v1},
}
